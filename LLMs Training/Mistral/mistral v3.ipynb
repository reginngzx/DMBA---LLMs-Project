{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae3c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load train and test data\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e748a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240815T010000Z</td>\n",
       "      <td>https://borneobulletin.com.bn/explosions-repor...</td>\n",
       "      <td>Explosions reported near two ships off Yemen :...</td>\n",
       "      <td>borneobulletin.com.bn</td>\n",
       "      <td>Brunei</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240716T194500Z</td>\n",
       "      <td>https://www.hindustantimes.com/india-news/crew...</td>\n",
       "      <td>Crew , including 13 Indians , still missing af...</td>\n",
       "      <td>hindustantimes.com</td>\n",
       "      <td>India</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20240809T100000Z</td>\n",
       "      <td>https://www.yahoo.com/news/multiple-attacks-ta...</td>\n",
       "      <td>Multiple attacks target merchant ship off Yeme...</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240717T041500Z</td>\n",
       "      <td>https://timesofoman.com/article/147862-oil-tan...</td>\n",
       "      <td>Oil tanker with 13 Indians on board sinks off ...</td>\n",
       "      <td>timesofoman.com</td>\n",
       "      <td>Oman</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240812T201500Z</td>\n",
       "      <td>https://menafn.com/1108546043/Multiple-Attacks...</td>\n",
       "      <td>Multiple Attacks Target Merchant Ship Off Yemen</td>\n",
       "      <td>menafn.com</td>\n",
       "      <td>Qatar</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                                URL  \\\n",
       "0  20240815T010000Z  https://borneobulletin.com.bn/explosions-repor...   \n",
       "1  20240716T194500Z  https://www.hindustantimes.com/india-news/crew...   \n",
       "2  20240809T100000Z  https://www.yahoo.com/news/multiple-attacks-ta...   \n",
       "3  20240717T041500Z  https://timesofoman.com/article/147862-oil-tan...   \n",
       "4  20240812T201500Z  https://menafn.com/1108546043/Multiple-Attacks...   \n",
       "\n",
       "                                               Title                 Source  \\\n",
       "0  Explosions reported near two ships off Yemen :...  borneobulletin.com.bn   \n",
       "1  Crew , including 13 Indians , still missing af...     hindustantimes.com   \n",
       "2  Multiple attacks target merchant ship off Yeme...              yahoo.com   \n",
       "3  Oil tanker with 13 Indians on board sinks off ...        timesofoman.com   \n",
       "4    Multiple Attacks Target Merchant Ship Off Yemen             menafn.com   \n",
       "\n",
       "         Country  Label  \n",
       "0         Brunei      2  \n",
       "1          India      2  \n",
       "2  United States      3  \n",
       "3           Oman      2  \n",
       "4          Qatar      3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7168586f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20221207T020000Z</td>\n",
       "      <td>https://www.rnz.co.nz/news/national/480280/eng...</td>\n",
       "      <td>Engineer fined over huge fire at Napier Port</td>\n",
       "      <td>rnz.co.nz</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20221221T150000Z</td>\n",
       "      <td>https://www.ship-technology.com/news/ictsi-lea...</td>\n",
       "      <td>ICTSI reaches 30 - year lease extension for Ba...</td>\n",
       "      <td>ship-technology.com</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20221018T084500Z</td>\n",
       "      <td>https://www.malaymail.com/news/money/mediaoutr...</td>\n",
       "      <td>DHL : Ocean freight rate moving towards manage...</td>\n",
       "      <td>malaymail.com</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20221028T151500Z</td>\n",
       "      <td>https://focustaiwan.tw/society/202210280021</td>\n",
       "      <td>Indonesians stuck on vessel in Kaohsiung set t...</td>\n",
       "      <td>focustaiwan.tw</td>\n",
       "      <td>Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20221018T104500Z</td>\n",
       "      <td>https://bdnews24.com/bangladesh/0ggpvbnije</td>\n",
       "      <td>Body found in container sent from Chattogram t...</td>\n",
       "      <td>bdnews24.com</td>\n",
       "      <td>Bangladesh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                                URL  \\\n",
       "0  20221207T020000Z  https://www.rnz.co.nz/news/national/480280/eng...   \n",
       "1  20221221T150000Z  https://www.ship-technology.com/news/ictsi-lea...   \n",
       "2  20221018T084500Z  https://www.malaymail.com/news/money/mediaoutr...   \n",
       "3  20221028T151500Z        https://focustaiwan.tw/society/202210280021   \n",
       "4  20221018T104500Z         https://bdnews24.com/bangladesh/0ggpvbnije   \n",
       "\n",
       "                                               Title               Source  \\\n",
       "0       Engineer fined over huge fire at Napier Port            rnz.co.nz   \n",
       "1  ICTSI reaches 30 - year lease extension for Ba...  ship-technology.com   \n",
       "2  DHL : Ocean freight rate moving towards manage...        malaymail.com   \n",
       "3  Indonesians stuck on vessel in Kaohsiung set t...       focustaiwan.tw   \n",
       "4  Body found in container sent from Chattogram t...         bdnews24.com   \n",
       "\n",
       "         Country  \n",
       "0            NaN  \n",
       "1  United States  \n",
       "2  United States  \n",
       "3         Taiwan  \n",
       "4     Bangladesh  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ac6b3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Regin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Regin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Regin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for text processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Download necessary resources for NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to clean text (remove stop words and lemmatize)\n",
    "def clean_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove punctuation and stop words, then apply lemmatization\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word.lower()) for word in tokens \n",
    "                      if word.lower() not in stop_words and word not in string.punctuation]\n",
    "    \n",
    "    # Join tokens back to a single string\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the cleaning function to 'title' columns in train and test data\n",
    "train_data['cleaned_title'] = train_data['Title'].apply(clean_text)\n",
    "test_data['cleaned_title'] = test_data['Title'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf57ffc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country</th>\n",
       "      <th>Label</th>\n",
       "      <th>cleaned_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240815T010000Z</td>\n",
       "      <td>https://borneobulletin.com.bn/explosions-repor...</td>\n",
       "      <td>Explosions reported near two ships off Yemen :...</td>\n",
       "      <td>borneobulletin.com.bn</td>\n",
       "      <td>Brunei</td>\n",
       "      <td>2</td>\n",
       "      <td>explosion reported near two ship yemen securit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240716T194500Z</td>\n",
       "      <td>https://www.hindustantimes.com/india-news/crew...</td>\n",
       "      <td>Crew , including 13 Indians , still missing af...</td>\n",
       "      <td>hindustantimes.com</td>\n",
       "      <td>India</td>\n",
       "      <td>2</td>\n",
       "      <td>crew including 13 indian still missing oil tan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20240809T100000Z</td>\n",
       "      <td>https://www.yahoo.com/news/multiple-attacks-ta...</td>\n",
       "      <td>Multiple attacks target merchant ship off Yeme...</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>3</td>\n",
       "      <td>multiple attack target merchant ship yemen uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240717T041500Z</td>\n",
       "      <td>https://timesofoman.com/article/147862-oil-tan...</td>\n",
       "      <td>Oil tanker with 13 Indians on board sinks off ...</td>\n",
       "      <td>timesofoman.com</td>\n",
       "      <td>Oman</td>\n",
       "      <td>2</td>\n",
       "      <td>oil tanker 13 indian board sink oman coast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240812T201500Z</td>\n",
       "      <td>https://menafn.com/1108546043/Multiple-Attacks...</td>\n",
       "      <td>Multiple Attacks Target Merchant Ship Off Yemen</td>\n",
       "      <td>menafn.com</td>\n",
       "      <td>Qatar</td>\n",
       "      <td>3</td>\n",
       "      <td>multiple attack target merchant ship yemen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                                URL  \\\n",
       "0  20240815T010000Z  https://borneobulletin.com.bn/explosions-repor...   \n",
       "1  20240716T194500Z  https://www.hindustantimes.com/india-news/crew...   \n",
       "2  20240809T100000Z  https://www.yahoo.com/news/multiple-attacks-ta...   \n",
       "3  20240717T041500Z  https://timesofoman.com/article/147862-oil-tan...   \n",
       "4  20240812T201500Z  https://menafn.com/1108546043/Multiple-Attacks...   \n",
       "\n",
       "                                               Title                 Source  \\\n",
       "0  Explosions reported near two ships off Yemen :...  borneobulletin.com.bn   \n",
       "1  Crew , including 13 Indians , still missing af...     hindustantimes.com   \n",
       "2  Multiple attacks target merchant ship off Yeme...              yahoo.com   \n",
       "3  Oil tanker with 13 Indians on board sinks off ...        timesofoman.com   \n",
       "4    Multiple Attacks Target Merchant Ship Off Yemen             menafn.com   \n",
       "\n",
       "         Country  Label                                      cleaned_title  \n",
       "0         Brunei      2  explosion reported near two ship yemen securit...  \n",
       "1          India      2  crew including 13 indian still missing oil tan...  \n",
       "2  United States      3  multiple attack target merchant ship yemen uni...  \n",
       "3           Oman      2         oil tanker 13 indian board sink oman coast  \n",
       "4          Qatar      3         multiple attack target merchant ship yemen  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f625f03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country</th>\n",
       "      <th>cleaned_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20221207T020000Z</td>\n",
       "      <td>https://www.rnz.co.nz/news/national/480280/eng...</td>\n",
       "      <td>Engineer fined over huge fire at Napier Port</td>\n",
       "      <td>rnz.co.nz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>engineer fined huge fire napier port</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20221221T150000Z</td>\n",
       "      <td>https://www.ship-technology.com/news/ictsi-lea...</td>\n",
       "      <td>ICTSI reaches 30 - year lease extension for Ba...</td>\n",
       "      <td>ship-technology.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>ictsi reach 30 year lease extension baltic con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20221018T084500Z</td>\n",
       "      <td>https://www.malaymail.com/news/money/mediaoutr...</td>\n",
       "      <td>DHL : Ocean freight rate moving towards manage...</td>\n",
       "      <td>malaymail.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>dhl ocean freight rate moving towards manageab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20221028T151500Z</td>\n",
       "      <td>https://focustaiwan.tw/society/202210280021</td>\n",
       "      <td>Indonesians stuck on vessel in Kaohsiung set t...</td>\n",
       "      <td>focustaiwan.tw</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>indonesian stuck vessel kaohsiung set return h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20221018T104500Z</td>\n",
       "      <td>https://bdnews24.com/bangladesh/0ggpvbnije</td>\n",
       "      <td>Body found in container sent from Chattogram t...</td>\n",
       "      <td>bdnews24.com</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>body found container sent chattogram malaysia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                                URL  \\\n",
       "0  20221207T020000Z  https://www.rnz.co.nz/news/national/480280/eng...   \n",
       "1  20221221T150000Z  https://www.ship-technology.com/news/ictsi-lea...   \n",
       "2  20221018T084500Z  https://www.malaymail.com/news/money/mediaoutr...   \n",
       "3  20221028T151500Z        https://focustaiwan.tw/society/202210280021   \n",
       "4  20221018T104500Z         https://bdnews24.com/bangladesh/0ggpvbnije   \n",
       "\n",
       "                                               Title               Source  \\\n",
       "0       Engineer fined over huge fire at Napier Port            rnz.co.nz   \n",
       "1  ICTSI reaches 30 - year lease extension for Ba...  ship-technology.com   \n",
       "2  DHL : Ocean freight rate moving towards manage...        malaymail.com   \n",
       "3  Indonesians stuck on vessel in Kaohsiung set t...       focustaiwan.tw   \n",
       "4  Body found in container sent from Chattogram t...         bdnews24.com   \n",
       "\n",
       "         Country                                      cleaned_title  \n",
       "0            NaN               engineer fined huge fire napier port  \n",
       "1  United States  ictsi reach 30 year lease extension baltic con...  \n",
       "2  United States  dhl ocean freight rate moving towards manageab...  \n",
       "3         Taiwan  indonesian stuck vessel kaohsiung set return h...  \n",
       "4     Bangladesh      body found container sent chattogram malaysia  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f28f700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b0f9501734408c9437303545473cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a923f5ffa3c148c389d35140c9919c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/143 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Regin\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Regin\\AppData\\Local\\Temp\\ipykernel_26608\\3928668391.py:55: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 12:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.964588</td>\n",
       "      <td>0.475524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.708649</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.653235</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5384615384615384\n",
      "Classification Report (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.45      0.82      0.58        17\n",
      "           3       0.69      0.97      0.80        34\n",
      "           4       0.00      0.00      0.00        11\n",
      "           6       0.00      0.00      0.00         9\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00         6\n",
      "           9       0.00      0.00      0.00         3\n",
      "          10       0.00      0.00      0.00         4\n",
      "          11       0.00      0.00      0.00        14\n",
      "          12       0.49      0.83      0.62        36\n",
      "\n",
      "    accuracy                           0.54       143\n",
      "   macro avg       0.15      0.24      0.18       143\n",
      "weighted avg       0.34      0.54      0.42       143\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35370a3d3959421d94031fff90391a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/713 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'updated_news_titles_with_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load the training data and updated news titles data\n",
    "train_df = pd.read_csv('training_dataset.csv')\n",
    "predict_df = pd.read_csv('updated_news_titles.csv')\n",
    "\n",
    "# Ensure the columns are correctly labeled in the training data\n",
    "train_df = train_df[['Title', 'LABEL']].rename(columns={'LABEL': 'labels'})\n",
    "\n",
    "# Split the training data into train and validation sets\n",
    "train_df, eval_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert DataFrames to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "eval_dataset = Dataset.from_pandas(eval_df)\n",
    "\n",
    "# Load the tokenizer and model with num_labels=14 to accommodate labels from 0 to 13\n",
    "model_name = \"distilbert-base-uncased\"  # Replace with \"mistralai/mistral\" if you have access\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=14)\n",
    "\n",
    "# Tokenize the data\n",
    "def preprocess_data(examples):\n",
    "    return tokenizer(examples[\"Title\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "# Tokenize both train and validation datasets\n",
    "train_dataset = train_dataset.map(preprocess_data, batched=True)\n",
    "eval_dataset = eval_dataset.map(preprocess_data, batched=True)\n",
    "\n",
    "# Training setup with evaluation strategy set to \"epoch\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",  # Enable evaluation after each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Define a compute_metrics function for evaluation\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "# Initialize the Trainer with both train and validation datasets\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "eval_predictions = trainer.predict(eval_dataset)\n",
    "eval_preds = eval_predictions.predictions.argmax(-1)\n",
    "\n",
    "# Generate and display the classification report and accuracy score for the validation set\n",
    "print(\"Validation Accuracy:\", accuracy_score(eval_df['labels'], eval_preds))\n",
    "print(\"Classification Report (Validation Set):\")\n",
    "print(classification_report(eval_df['labels'], eval_preds))\n",
    "\n",
    "# Prepare the predict dataset (updated news titles)\n",
    "predict_df = predict_df[['Title']]\n",
    "predict_dataset = Dataset.from_pandas(predict_df)\n",
    "predict_dataset = predict_dataset.map(preprocess_data, batched=True)\n",
    "\n",
    "# Predict on the updated news titles\n",
    "predict_results = trainer.predict(predict_dataset)\n",
    "predicted_labels = predict_results.predictions.argmax(-1)\n",
    "\n",
    "# Save the predictions to a new CSV file\n",
    "predict_df['Predicted_Label'] = predicted_labels\n",
    "predict_df.to_csv('updated_news_titles_with_predictions.csv', index=False)\n",
    "print(\"Predictions saved to 'updated_news_titles_with_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d41e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1ad8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d8133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a59be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d869bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2933ab03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dcaaf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ccdf0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2562bd98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
