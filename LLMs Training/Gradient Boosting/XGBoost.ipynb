{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Dataset - Remove stop word + Apply Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load train and test data\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240815T010000Z</td>\n",
       "      <td>https://borneobulletin.com.bn/explosions-repor...</td>\n",
       "      <td>Explosions reported near two ships off Yemen :...</td>\n",
       "      <td>borneobulletin.com.bn</td>\n",
       "      <td>Brunei</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240716T194500Z</td>\n",
       "      <td>https://www.hindustantimes.com/india-news/crew...</td>\n",
       "      <td>Crew , including 13 Indians , still missing af...</td>\n",
       "      <td>hindustantimes.com</td>\n",
       "      <td>India</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20240809T100000Z</td>\n",
       "      <td>https://www.yahoo.com/news/multiple-attacks-ta...</td>\n",
       "      <td>Multiple attacks target merchant ship off Yeme...</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240717T041500Z</td>\n",
       "      <td>https://timesofoman.com/article/147862-oil-tan...</td>\n",
       "      <td>Oil tanker with 13 Indians on board sinks off ...</td>\n",
       "      <td>timesofoman.com</td>\n",
       "      <td>Oman</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240812T201500Z</td>\n",
       "      <td>https://menafn.com/1108546043/Multiple-Attacks...</td>\n",
       "      <td>Multiple Attacks Target Merchant Ship Off Yemen</td>\n",
       "      <td>menafn.com</td>\n",
       "      <td>Qatar</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                                URL  \\\n",
       "0  20240815T010000Z  https://borneobulletin.com.bn/explosions-repor...   \n",
       "1  20240716T194500Z  https://www.hindustantimes.com/india-news/crew...   \n",
       "2  20240809T100000Z  https://www.yahoo.com/news/multiple-attacks-ta...   \n",
       "3  20240717T041500Z  https://timesofoman.com/article/147862-oil-tan...   \n",
       "4  20240812T201500Z  https://menafn.com/1108546043/Multiple-Attacks...   \n",
       "\n",
       "                                               Title                 Source  \\\n",
       "0  Explosions reported near two ships off Yemen :...  borneobulletin.com.bn   \n",
       "1  Crew , including 13 Indians , still missing af...     hindustantimes.com   \n",
       "2  Multiple attacks target merchant ship off Yeme...              yahoo.com   \n",
       "3  Oil tanker with 13 Indians on board sinks off ...        timesofoman.com   \n",
       "4    Multiple Attacks Target Merchant Ship Off Yemen             menafn.com   \n",
       "\n",
       "         Country  Label  \n",
       "0         Brunei      2  \n",
       "1          India      2  \n",
       "2  United States      3  \n",
       "3           Oman      2  \n",
       "4          Qatar      3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20221207T020000Z</td>\n",
       "      <td>https://www.rnz.co.nz/news/national/480280/eng...</td>\n",
       "      <td>Engineer fined over huge fire at Napier Port</td>\n",
       "      <td>rnz.co.nz</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20221221T150000Z</td>\n",
       "      <td>https://www.ship-technology.com/news/ictsi-lea...</td>\n",
       "      <td>ICTSI reaches 30 - year lease extension for Ba...</td>\n",
       "      <td>ship-technology.com</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20221018T084500Z</td>\n",
       "      <td>https://www.malaymail.com/news/money/mediaoutr...</td>\n",
       "      <td>DHL : Ocean freight rate moving towards manage...</td>\n",
       "      <td>malaymail.com</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20221028T151500Z</td>\n",
       "      <td>https://focustaiwan.tw/society/202210280021</td>\n",
       "      <td>Indonesians stuck on vessel in Kaohsiung set t...</td>\n",
       "      <td>focustaiwan.tw</td>\n",
       "      <td>Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20221018T104500Z</td>\n",
       "      <td>https://bdnews24.com/bangladesh/0ggpvbnije</td>\n",
       "      <td>Body found in container sent from Chattogram t...</td>\n",
       "      <td>bdnews24.com</td>\n",
       "      <td>Bangladesh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                                URL  \\\n",
       "0  20221207T020000Z  https://www.rnz.co.nz/news/national/480280/eng...   \n",
       "1  20221221T150000Z  https://www.ship-technology.com/news/ictsi-lea...   \n",
       "2  20221018T084500Z  https://www.malaymail.com/news/money/mediaoutr...   \n",
       "3  20221028T151500Z        https://focustaiwan.tw/society/202210280021   \n",
       "4  20221018T104500Z         https://bdnews24.com/bangladesh/0ggpvbnije   \n",
       "\n",
       "                                               Title               Source  \\\n",
       "0       Engineer fined over huge fire at Napier Port            rnz.co.nz   \n",
       "1  ICTSI reaches 30 - year lease extension for Ba...  ship-technology.com   \n",
       "2  DHL : Ocean freight rate moving towards manage...        malaymail.com   \n",
       "3  Indonesians stuck on vessel in Kaohsiung set t...       focustaiwan.tw   \n",
       "4  Body found in container sent from Chattogram t...         bdnews24.com   \n",
       "\n",
       "         Country  \n",
       "0            NaN  \n",
       "1  United States  \n",
       "2  United States  \n",
       "3         Taiwan  \n",
       "4     Bangladesh  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for text processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Download necessary resources for NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to clean text (remove stop words and lemmatize)\n",
    "def clean_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove punctuation and stop words, then apply lemmatization\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word.lower()) for word in tokens \n",
    "                      if word.lower() not in stop_words and word not in string.punctuation]\n",
    "    \n",
    "    # Join tokens back to a single string\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the cleaning function to 'title' columns in train and test data\n",
    "train_data['cleaned_title'] = train_data['Title'].apply(clean_text)\n",
    "test_data['cleaned_title'] = test_data['Title'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country</th>\n",
       "      <th>Label</th>\n",
       "      <th>cleaned_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240815T010000Z</td>\n",
       "      <td>https://borneobulletin.com.bn/explosions-repor...</td>\n",
       "      <td>Explosions reported near two ships off Yemen :...</td>\n",
       "      <td>borneobulletin.com.bn</td>\n",
       "      <td>Brunei</td>\n",
       "      <td>2</td>\n",
       "      <td>explosion reported near two ship yemen securit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240716T194500Z</td>\n",
       "      <td>https://www.hindustantimes.com/india-news/crew...</td>\n",
       "      <td>Crew , including 13 Indians , still missing af...</td>\n",
       "      <td>hindustantimes.com</td>\n",
       "      <td>India</td>\n",
       "      <td>2</td>\n",
       "      <td>crew including 13 indian still missing oil tan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20240809T100000Z</td>\n",
       "      <td>https://www.yahoo.com/news/multiple-attacks-ta...</td>\n",
       "      <td>Multiple attacks target merchant ship off Yeme...</td>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>3</td>\n",
       "      <td>multiple attack target merchant ship yemen uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240717T041500Z</td>\n",
       "      <td>https://timesofoman.com/article/147862-oil-tan...</td>\n",
       "      <td>Oil tanker with 13 Indians on board sinks off ...</td>\n",
       "      <td>timesofoman.com</td>\n",
       "      <td>Oman</td>\n",
       "      <td>2</td>\n",
       "      <td>oil tanker 13 indian board sink oman coast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240812T201500Z</td>\n",
       "      <td>https://menafn.com/1108546043/Multiple-Attacks...</td>\n",
       "      <td>Multiple Attacks Target Merchant Ship Off Yemen</td>\n",
       "      <td>menafn.com</td>\n",
       "      <td>Qatar</td>\n",
       "      <td>3</td>\n",
       "      <td>multiple attack target merchant ship yemen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                                URL  \\\n",
       "0  20240815T010000Z  https://borneobulletin.com.bn/explosions-repor...   \n",
       "1  20240716T194500Z  https://www.hindustantimes.com/india-news/crew...   \n",
       "2  20240809T100000Z  https://www.yahoo.com/news/multiple-attacks-ta...   \n",
       "3  20240717T041500Z  https://timesofoman.com/article/147862-oil-tan...   \n",
       "4  20240812T201500Z  https://menafn.com/1108546043/Multiple-Attacks...   \n",
       "\n",
       "                                               Title                 Source  \\\n",
       "0  Explosions reported near two ships off Yemen :...  borneobulletin.com.bn   \n",
       "1  Crew , including 13 Indians , still missing af...     hindustantimes.com   \n",
       "2  Multiple attacks target merchant ship off Yeme...              yahoo.com   \n",
       "3  Oil tanker with 13 Indians on board sinks off ...        timesofoman.com   \n",
       "4    Multiple Attacks Target Merchant Ship Off Yemen             menafn.com   \n",
       "\n",
       "         Country  Label                                      cleaned_title  \n",
       "0         Brunei      2  explosion reported near two ship yemen securit...  \n",
       "1          India      2  crew including 13 indian still missing oil tan...  \n",
       "2  United States      3  multiple attack target merchant ship yemen uni...  \n",
       "3           Oman      2         oil tanker 13 indian board sink oman coast  \n",
       "4          Qatar      3         multiple attack target merchant ship yemen  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country</th>\n",
       "      <th>cleaned_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20221207T020000Z</td>\n",
       "      <td>https://www.rnz.co.nz/news/national/480280/eng...</td>\n",
       "      <td>Engineer fined over huge fire at Napier Port</td>\n",
       "      <td>rnz.co.nz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>engineer fined huge fire napier port</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20221221T150000Z</td>\n",
       "      <td>https://www.ship-technology.com/news/ictsi-lea...</td>\n",
       "      <td>ICTSI reaches 30 - year lease extension for Ba...</td>\n",
       "      <td>ship-technology.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>ictsi reach 30 year lease extension baltic con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20221018T084500Z</td>\n",
       "      <td>https://www.malaymail.com/news/money/mediaoutr...</td>\n",
       "      <td>DHL : Ocean freight rate moving towards manage...</td>\n",
       "      <td>malaymail.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>dhl ocean freight rate moving towards manageab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20221028T151500Z</td>\n",
       "      <td>https://focustaiwan.tw/society/202210280021</td>\n",
       "      <td>Indonesians stuck on vessel in Kaohsiung set t...</td>\n",
       "      <td>focustaiwan.tw</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>indonesian stuck vessel kaohsiung set return h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20221018T104500Z</td>\n",
       "      <td>https://bdnews24.com/bangladesh/0ggpvbnije</td>\n",
       "      <td>Body found in container sent from Chattogram t...</td>\n",
       "      <td>bdnews24.com</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>body found container sent chattogram malaysia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                                URL  \\\n",
       "0  20221207T020000Z  https://www.rnz.co.nz/news/national/480280/eng...   \n",
       "1  20221221T150000Z  https://www.ship-technology.com/news/ictsi-lea...   \n",
       "2  20221018T084500Z  https://www.malaymail.com/news/money/mediaoutr...   \n",
       "3  20221028T151500Z        https://focustaiwan.tw/society/202210280021   \n",
       "4  20221018T104500Z         https://bdnews24.com/bangladesh/0ggpvbnije   \n",
       "\n",
       "                                               Title               Source  \\\n",
       "0       Engineer fined over huge fire at Napier Port            rnz.co.nz   \n",
       "1  ICTSI reaches 30 - year lease extension for Ba...  ship-technology.com   \n",
       "2  DHL : Ocean freight rate moving towards manage...        malaymail.com   \n",
       "3  Indonesians stuck on vessel in Kaohsiung set t...       focustaiwan.tw   \n",
       "4  Body found in container sent from Chattogram t...         bdnews24.com   \n",
       "\n",
       "         Country                                      cleaned_title  \n",
       "0            NaN               engineer fined huge fire napier port  \n",
       "1  United States  ictsi reach 30 year lease extension baltic con...  \n",
       "2  United States  dhl ocean freight rate moving towards manageab...  \n",
       "3         Taiwan  indonesian stuck vessel kaohsiung set return h...  \n",
       "4     Bangladesh      body found container sent chattogram malaysia  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Split train_data into train and validation sets\n",
    "X_full = train_data['cleaned_title']\n",
    "y_full = train_data['Label'] - 1  # Adjust labels to start from 0\n",
    "\n",
    "# Create training and validation sets\n",
    "X_train_raw, X_val_raw, y_train, y_val = train_test_split(X_full, y_full, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Vectorize the data\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_val = vectorizer.transform(X_val_raw)\n",
    "X_test = vectorizer.transform(test_data['cleaned_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Best AUC Score: 0.7251508208531678\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define parameter grid and perform grid search with XGBoost\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize XGBoost model\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Set up GridSearchCV with AUC scoring for multiclass (One-vs-Rest)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model, \n",
    "    param_grid=param_grid, \n",
    "    scoring='roc_auc_ovr', \n",
    "    cv=3, \n",
    "    n_jobs=-1, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit grid search on training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best AUC Score:\", grid_search.best_score_)\n",
    "\n",
    "# Use the best model from grid search\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best thresholds for each class...\n",
      "Class 1: Best Threshold = 0.15000000000000002, Best AUC = 0.625\n",
      "Class 2: Best Threshold = 0.2, Best AUC = 0.7959714100064977\n",
      "Class 3: Best Threshold = 0.15000000000000002, Best AUC = 0.9146341463414633\n",
      "Class 4: Best Threshold = 0.15000000000000002, Best AUC = 0.8463455149501661\n",
      "Skipping class 5 due to lack of positive/negative examples.\n",
      "Class 6: Best Threshold = 0.05, Best AUC = 0.8953900709219859\n",
      "Class 7: Best Threshold = 0.1, Best AUC = 0.5\n",
      "Class 8: Best Threshold = 0.25, Best AUC = 0.5\n",
      "Class 9: Best Threshold = 0.30000000000000004, Best AUC = 0.5\n",
      "Class 10: Best Threshold = 0.1, Best AUC = 0.6666666666666666\n",
      "Class 11: Best Threshold = 0.2, Best AUC = 0.7\n",
      "Class 12: Best Threshold = 0.1, Best AUC = 0.7673297166968053\n",
      "Class 13: Best Threshold = 0.05, Best AUC = 0.7920962199312714\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Predict probabilities on the validation set\n",
    "y_proba_val = best_model.predict_proba(X_val)\n",
    "\n",
    "# Step 5: Find optimal thresholds for each class using the validation set\n",
    "class_thresholds = {}\n",
    "num_classes = y_proba_val.shape[1]\n",
    "\n",
    "print(\"Finding best thresholds for each class...\")\n",
    "for class_index in range(num_classes):\n",
    "    best_threshold = 0.5  # Default threshold\n",
    "    best_auc = 0\n",
    "    thresholds = [i * 0.05 for i in range(1, 20)]\n",
    "    \n",
    "    # Convert y_val to binary for the current class\n",
    "    y_val_binary = (y_val == class_index).astype(int)\n",
    "    \n",
    "    # Check if y_val_binary has only one unique value (all 0s or all 1s)\n",
    "    if len(np.unique(y_val_binary)) == 1:\n",
    "        print(f\"Skipping class {class_index + 1} due to lack of positive/negative examples.\")\n",
    "        class_thresholds[class_index] = best_threshold\n",
    "        continue\n",
    "    \n",
    "    # Loop through possible thresholds for this class\n",
    "    for threshold in thresholds:\n",
    "        y_pred_threshold = (y_proba_val[:, class_index] >= threshold).astype(int)\n",
    "        auc = roc_auc_score(y_val_binary, y_pred_threshold)\n",
    "        \n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    # Store the best threshold for the current class\n",
    "    class_thresholds[class_index] = best_threshold\n",
    "    print(f\"Class {class_index + 1}: Best Threshold = {best_threshold}, Best AUC = {best_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Predict labels on the test set using class-specific thresholds\n",
    "y_proba_test = best_model.predict_proba(X_test)\n",
    "y_pred_test = []\n",
    "\n",
    "for i in range(y_proba_test.shape[0]):\n",
    "    class_predictions = []\n",
    "    \n",
    "    for class_index in range(num_classes):\n",
    "        # Check if probability exceeds the threshold for this class\n",
    "        if y_proba_test[i, class_index] >= class_thresholds[class_index]:\n",
    "            class_predictions.append((class_index, y_proba_test[i, class_index]))\n",
    "    \n",
    "    # If multiple classes exceed thresholds, pick the one with the highest probability\n",
    "    if class_predictions:\n",
    "        best_class = max(class_predictions, key=lambda x: x[1])[0]\n",
    "    else:\n",
    "        # If no class exceeds thresholds, pick the class with the highest probability\n",
    "        best_class = np.argmax(y_proba_test[i, :])\n",
    "    \n",
    "    y_pred_test.append(best_class + 1)  # Convert back to original label range (1-13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Add predictions to the test data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_title\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_title\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Assuming 'cleaned_title' is already in test_data\u001b[39;00m\n\u001b[0;32m      3\u001b[0m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted_Label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_pred_test  \u001b[38;5;66;03m# Add the predicted labels\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Save the entire test_data with all original columns and the new columns to predictions.csv\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Add predictions to the test data\n",
    "test_data['cleaned_title'] = test_data['cleaned_title']  # Assuming 'cleaned_title' is already in test_data\n",
    "test_data['Predicted_Label'] = y_pred_test  # Add the predicted labels\n",
    "\n",
    "# Save the entire test_data with all original columns and the new columns to predictions.csv\n",
    "test_data.to_csv('xgb_predictions.csv', index=False)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(test_data.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
