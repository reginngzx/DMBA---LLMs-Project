{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"i7U0RdqNz7I5"},"outputs":[],"source":["zsniimport pandas as pd\n","\n","# Load train and test data\n","train_data = pd.read_csv('train_data.csv')\n","test_data = pd.read_csv('test_data.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0hdTlbq-z7I7","outputId":"2292e84e-9927-4acd-f7d4-6a7e91b29b6c"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\aaron\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["# Import necessary libraries for text processing\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","import string\n","\n","# Download necessary resources for NLTK\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Initialize stopwords and lemmatizer\n","stop_words = set(stopwords.words('english'))\n","lemmatizer = WordNetLemmatizer()\n","\n","# Function to clean text (remove stop words and lemmatize)\n","def clean_text(text):\n","    # Tokenize the text\n","    tokens = nltk.word_tokenize(text)\n","\n","    # Remove punctuation and stop words, then apply lemmatization\n","    cleaned_tokens = [lemmatizer.lemmatize(word.lower()) for word in tokens\n","                      if word.lower() not in stop_words and word not in string.punctuation]\n","\n","    # Join tokens back to a single string\n","    cleaned_text = ' '.join(cleaned_tokens)\n","    return cleaned_text\n","\n","# Apply the cleaning function to 'title' columns in train and test data\n","train_data['cleaned_title'] = train_data['Title'].apply(clean_text)\n","test_data['cleaned_title'] = test_data['Title'].apply(clean_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67irJ79Mz7I7"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, make_scorer\n","from sklearn.preprocessing import LabelBinarizer\n","import numpy as np\n","\n","# Step 1: Split data into training and validation sets\n","X_full = train_data['cleaned_title']\n","y_full = train_data['Label'] - 1  # Adjust labels to start from 0\n","\n","X_train_raw, X_val_raw, y_train, y_val = train_test_split(X_full, y_full, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nT-UFdW6z7I8"},"outputs":[],"source":["# Step 2: Vectorize the data\n","vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))  # Use bigrams if preferred\n","X_train = vectorizer.fit_transform(X_train_raw)\n","X_val = vectorizer.transform(X_val_raw)\n","X_test = vectorizer.transform(test_data['cleaned_title'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a7bVO3HUz7I8","outputId":"89c4d9b3-d887-40eb-f355-aa1009ecd185"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 3 candidates, totalling 9 fits\n","Best Parameters: {'alpha': 0.1}\n","Best AUC Score from Grid Search: 0.8076588784948955\n","Validation Accuracy with Naive Bayes: 0.55\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      0.25      0.40         4\n","           1       0.62      0.68      0.65        19\n","           2       0.57      0.94      0.71        18\n","           3       0.50      0.43      0.46        14\n","           5       0.80      0.67      0.73         6\n","           6       0.00      0.00      0.00         1\n","           7       1.00      0.25      0.40         4\n","           8       0.00      0.00      0.00         2\n","           9       0.00      0.00      0.00         3\n","          10       0.40      0.40      0.40         5\n","          11       0.46      0.52      0.49        21\n","          12       0.00      0.00      0.00         3\n","\n","    accuracy                           0.55       100\n","   macro avg       0.45      0.35      0.35       100\n","weighted avg       0.53      0.55      0.51       100\n","\n","AUC for class 1: 0.7083333333333333\n","AUC for class 2: 0.9090318388564003\n","AUC for class 3: 0.9715447154471545\n","AUC for class 4: 0.882890365448505\n","Skipping AUC for class 5 due to single-class issue.\n","AUC for class 6: 0.9734042553191489\n","AUC for class 7: 0.7474747474747474\n","AUC for class 8: 0.9765625\n","AUC for class 9: 0.8418367346938775\n","AUC for class 10: 0.7869415807560137\n","AUC for class 11: 0.8863157894736842\n","AUC for class 12: 0.8270042194092827\n","AUC for class 13: 0.872852233676976\n","Average AUC Score across all classes: 0.8653493594907603\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\aaron\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","c:\\Users\\aaron\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","c:\\Users\\aaron\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["# Step 3: Perform Grid Search to find the best alpha using AUC as the scoring metric\n","param_grid = {'alpha': [0.1, 0.5, 1.0]}\n","auc_scorer = make_scorer(roc_auc_score, multi_class='ovr', needs_proba=True)\n","nb_model = MultinomialNB()\n","\n","grid_search = GridSearchCV(estimator=nb_model, param_grid=param_grid, scoring=auc_scorer, cv=3, verbose=1)\n","grid_search.fit(X_train, y_train)\n","\n","# Use the best model from GridSearchCV\n","best_nb_model = grid_search.best_estimator_\n","print(\"Best Parameters:\", grid_search.best_params_)\n","print(\"Best AUC Score from Grid Search:\", grid_search.best_score_)\n","\n","# Step 4: Evaluate on the validation set using the best model\n","y_val_pred = best_nb_model.predict(X_val)\n","y_val_proba = best_nb_model.predict_proba(X_val)  # Get probabilities for AUC scoring\n","\n","# Calculate accuracy\n","val_accuracy = accuracy_score(y_val, y_val_pred)\n","print(f\"Validation Accuracy with Naive Bayes: {val_accuracy}\")\n","print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n","\n","# Step 4a: Ensure all classes are represented in y_val_proba\n","num_classes = len(np.unique(y_train))  # Get total number of classes from y_train\n","if y_val_proba.shape[1] < num_classes:\n","    # Add missing class columns with zeros\n","    missing_classes = num_classes - y_val_proba.shape[1]\n","    y_val_proba = np.hstack([y_val_proba, np.zeros((y_val_proba.shape[0], missing_classes))])\n","\n","# Binarize y_val for per-class AUC calculation with explicit number of classes\n","lb = LabelBinarizer()\n","lb.fit(range(num_classes))  # Fit all classes\n","y_val_binarized = lb.transform(y_val)\n","\n","# Calculate AUC score for each class and skip single-class cases\n","auc_scores = []\n","for i in range(num_classes):\n","    if len(np.unique(y_val_binarized[:, i])) > 1:  # Check if the class has both positive and negative samples\n","        auc = roc_auc_score(y_val_binarized[:, i], y_val_proba[:, i])\n","        auc_scores.append(auc)\n","        print(f\"AUC for class {i + 1}: {auc}\")\n","    else:\n","        print(f\"Skipping AUC for class {i + 1} due to single-class issue.\")\n","\n","# Calculate the average AUC score if there are valid scores\n","if auc_scores:\n","    average_auc = np.mean(auc_scores)\n","    print(f\"Average AUC Score across all classes: {average_auc}\")\n","else:\n","    print(\"AUC calculation skipped due to single-class issue in all classes.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2d9Lzx6Hz7I8","outputId":"ba0ab3a3-4a45-4c1d-dff4-bcbe3e5250c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                       cleaned_title  Predicted_Label\n","0               engineer fined huge fire napier port                2\n","1  ictsi reach 30 year lease extension baltic con...               12\n","2  dhl ocean freight rate moving towards manageab...                2\n","3  indonesian stuck vessel kaohsiung set return h...                4\n","4      body found container sent chattogram malaysia                4\n"]}],"source":["# Step 5: Predict on the test set\n","y_test_proba = best_nb_model.predict_proba(X_test)\n","y_test_pred = np.argmax(y_test_proba, axis=1)  # Select class with the highest probability\n","\n","# Adjust back to original label range and save predictions\n","test_data['Predicted_Label'] = y_test_pred + 1  # Convert back to 1-based labels\n","test_data.to_csv('nb_predictions.csv', index=False)\n","print(test_data[['cleaned_title', 'Predicted_Label']].head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gW1d8pWuz7I8","outputId":"f6bbc507-73b6-40d8-e39c-8144c10284b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy Score: 46.95%\n"]}],"source":["# Load the prediction and test data\n","nb_predictions_df = pd.read_csv('nb_predictions.csv')\n","test_data_df = pd.read_excel('Test Data (with labels).xlsx')\n","\n","# Rename columns in test data for clarity\n","test_data_df.columns = ['Date', 'URL', 'Title', 'Source', 'Country', 'Actual_Label']\n","\n","# Sort and merge both dataframes on the 'URL' column for alignment\n","merged_df = pd.merge(nb_predictions_df, test_data_df, on='URL', suffixes=('_pred', '_actual'))\n","\n","# Calculate the accuracy score\n","accuracy = (merged_df['Predicted_Label'] == merged_df['Actual_Label']).mean()\n","\n","# Print the accuracy\n","print(f\"Accuracy Score: {accuracy * 100:.2f}%\")"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}